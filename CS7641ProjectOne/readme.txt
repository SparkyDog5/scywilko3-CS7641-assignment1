CS7641 Machine Learning � Spring 2021
Assignment 1 � Supervised Learning
Steve Cywilko - scywilko3@gatech.edu - GT ID: 903294864

**README FILE**

**Software/Tools**

The Python code, along with data files, some Weka leftover material, and other supporting information, is located in:
https://github.com/SparkyDog5/scywilko3-CS7641-assignment1.git
The main directory is CS7641ProjectOne

Details:
For the majority of this project, I used the Scikit-learn package of Machine Learning tools, in Python 3.7.  (https://scikit-learn.org/stable/about.html#citing-scikit-learn)

|Algorithm -->	Scikit-learn Algorithm
|Decision Trees --> DecisionTreeClassifier
|Neural Networks --> MLPClassifier
|Boosting --> AdaBoostClassifier
|Support Vector Machines --> SVC
|k-Nearest Neighbors --> KNeighborsClassifier

Prior to switching to Scikit-learn, I initially used the Weka (Waikato Environment for Knowledge Analysis) GUI tool, version 3.8.3.  A download is available at https://www.cs.waikato.ac.nz/ml/weka/downloading.html.
(Weka requires an installation of Java on your machine.  I used the version for 64-bit Windows, and already had Java 1.8 installed.)
When executing the Weka tool, I used both the Explorer tool and the Experimenter tool.  Both are available from the main menu.
The Explorer tool was used during my initial review of the data that became part of the assignment.  It allowed me to �play� with each of the algorithms, and adjust the hyperparameters to see how the resulting model was affected.  It also allowed me to adjust the attributes of the files I used, to determine which attributes were best suited to work with the experiments. 
The algorithms in Weka do not use the same terminology as those presented in the class.  The following were the algorithms used for each of the algorithms in the assignment:

|Algorithm -->	Weka Algorithm
|Decision Trees --> J48 (a.k.a. C4.5)
|Neural Networks --> MultilayerPerceptron
|Boosting --> AdaBoostM1
|Support Vector Machines --> SMO (Sequential Minimal Optimization)
|k-Nearest Neighbors --> IBk

The Experimenter tool was then used to perform evaluations of each of the algorithms.  This included the determination of learning curves associated with train/test ratios, and comparisons of performance when multiple hyperparameters were manipulated.  In essence, the tool implemented the necessary looping, and provided output that fed the resulting analysis.
The graphs were generated by taking the output from the Experimenter runs and plugging them into Excel.  (Excel arguably provides more readable graphs than Weka does.)

As noted above, I also used Microsoft Excel for 1) Building out the CSV files for my datasets (splitting train and test, for example, using Excel's "random" formula), and 2) on occasion, "cleaning up" graphs for use in the project paper.

**Data**

For the Pima Native American analysis, I used a single dataset from Kaggle.com.  That data is available here: https://www.kaggle.com/uciml/pima-indians-diabetes-database.  (Please note that it is available from a large number of sources, in addition to Kaggle.)  
I updated the target class variable values in the dataset from �0� and �1� to �tested_negative� and �tested_positive� to facilitate testing.

For the Baseball Hall of Fame analysis, I gathered data from two primary sources � the �SeanLahman� baseball database (http://www.seanlahman.com/baseball-archive/statistics) and Baseball Reference (https://www.baseball-reference.com).
Using those two databases, I built a combined file that included players from all years that professional baseball has been played, along with a number of statistics associated with each.  I also incorporated target classes that could be used to determine if a player was never considered for the Hall of Fame, considered but never inducted, or inducted.  These designations were necessary to make sure the data was not significantly imbalanced.  (For example, there are a great many players who played fewer than 5 games in their entire career.  Including those players in the analysis simply slowed things down with no appreciable benefit.)


Please note that both .csv files and .arff files are available in the repository. (.arff files are the �Weka format� files containing the training and test data.)  Both can be used in the Weka UI.

Also:  There is a reference to "noWAR" in a few of the file names.  This is because there is a baseball stat called "WAR" (Wins Above Replacement) which is used to determine the "value" of a player vs. the player's peers.  Initial files included that statistic, but they were later updated to remove it.  Hence the reference in the file name.